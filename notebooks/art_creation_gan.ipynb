{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I’m Something of a Painter Myself – Monet GAN\n",
    "#### Author: James Coffey   \n",
    "#### Date: 2025‑07‑30\n",
    "#### Challenge URL: [I’m Something of a Painter Myself](https://www.kaggle.com/competitions/gan-getting-started)\n",
    "\n",
    "# Discussion – Monet CycleGAN (Public MiFID 75.00706)\n",
    "\n",
    "## Key Implementation Decisions\n",
    "\n",
    "### Data pipeline\n",
    "\n",
    "* **TFRecord → `tf.data`** — I read the Monet & photo shards straight from\n",
    "  Kaggle GCS and stream‑prefetch them on TPU.  Parsing converts JPEG bytes to\n",
    "  `float32` in the `[-1, 1]` range.\n",
    "* **Light augmentations** — random flip, brightness/contrast/hue jitter, and the\n",
    "  canonical 286 → 256 random crop (matching the original CycleGAN tutorial).\n",
    "\n",
    "### Model architecture\n",
    "\n",
    "* **Encoder–decoder generators with skip connections** (8 down‑sampling + 7\n",
    "  up‑sampling blocks) built entirely from Conv/ConvT layers.  Instance‑norm\n",
    "  (`GroupNorm(groups=-1)`) is used instead of batch‑norm.\n",
    "* **70 × 70 PatchGAN discriminators** — three stride‑2 convs plus stride‑1\n",
    "  layers yield a `(30, 30, 1)` logit map, enforcing local texture realism.\n",
    "\n",
    "### Optimization & training\n",
    "\n",
    "* **Separate optimizers** for generators and discriminators\n",
    "  (Adam 2 e‑4 / β₁ = 0.5).\n",
    "* **BCE‑with‑logits GAN loss** (not LS‑GAN) and standard cycle + identity\n",
    "  penalties (`λ_cycle = 10`, `λ_id = 0.5 λ_cycle`).\n",
    "* **Mixed precision disabled** for the leaderboard run; it’s wired up but\n",
    "  commented out to avoid numerical jitter observed in early experiments.\n",
    "\n",
    "### Submission workflow\n",
    "\n",
    "Generated images are first saved to a local `/kaggle/working/images` folder and\n",
    "then zipped via `shutil.make_archive` to meet Kaggle’s single‑file output rule.\n",
    "\n",
    "## Observations about the Data\n",
    "\n",
    "1. **Domain imbalance** — only 300 Monet paintings versus 7 028 photos.  I\n",
    "   relied on cycle‑consistency plus heavier color jitter on the Monet side to\n",
    "   combat over‑fitting.\n",
    "2. **Palette skew** — Monet HSV histograms lean heavily toward greens and soft\n",
    "   blues; even a ±5 % hue jitter noticeably broadens color coverage.\n",
    "3. **Clean dataset** — no corrupt JPEGs or duplicate hashes, so no additional\n",
    "   filtering was necessary.\n",
    "\n",
    "## Model Insights\n",
    "\n",
    "* **Identity‑loss weight matters** — using `0.5 λ_cycle` kept skies and light\n",
    "  areas from color‑shifting, without slowing convergence.\n",
    "* **InstanceNorm beats BatchNorm** for tiny TPU batches; BatchNorm variants\n",
    "  produce visible color flicker and higher MiFID.\n",
    "\n",
    "## Results\n",
    "\n",
    "* **Public leaderboard**: **75.00706 MiFID** (lower = better) at the time of\n",
    "  writing.\n",
    "* **Runtime**: 24 epochs completed in ~2 h 40 m on a single TPU v3‑8.\n",
    "* **Visual quality**: foliage, water, and skies adopt a convincing Monet\n",
    "  brush‑stroke texture (consistent with the Monet training set).\n",
    "\n",
    "\n",
    "## Future Work\n",
    "\n",
    "1. **Self‑attention layers** in the deepest encoder blocks to capture larger\n",
    "   context.\n",
    "2. **CUT / FastCUT** to halve training time while maintaining FID/MiFID.\n",
    "3. **Re‑enable mixed precision** now that the graph is naming‑clean; this should\n",
    "   shave \\~20 % off runtime.\n",
    "4. **Multi‑style pre‑training** (Monet + Van Gogh + Cézanne) followed by\n",
    "   fine‑tuning to Monet‑only for better generalization.\n",
    "\n",
    "With a straightforward encoder–decoder CycleGAN, disciplined hyper‑parameters,\n",
    "and TPU‑optimized data loading, I achieved a MiFID of ≈75 without exotic tricks.\n",
    "The remaining gap to state‑of‑the‑art now feels like an engineering iteration\n",
    "rather than a research leap.\n",
    "\n",
    "# Imports & Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-06T22:37:30.706Z",
     "iopub.execute_input": "2025-08-06T22:37:11.131397Z",
     "iopub.status.busy": "2025-08-06T22:37:11.130996Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogle() is written to STDERR\n",
      "E0000 00:00:1754519838.464572      10 common_lib.cc:612] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n",
      "=== Source Location Trace: === \n",
      "learning/45eac/tfrc/runtime/common_lib.cc:230\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "import matplotlib.pyplot as plt\n",
    "from art_creation_gan import AUTO, SEED\n",
    "\n",
    "\n",
    "# Make randomness repeatable across hosts and replicas\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPU Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art_creation_gan import detect_tpu\n",
    "\n",
    "strategy = detect_tpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecord Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-06T22:37:30.706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from art_creation_gan import make_dataset\n",
    "\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path()\n",
    "MONET_TFREC = tf.io.gfile.glob(f\"{GCS_PATH}/monet_tfrec/*.tfrec\")\n",
    "PHOTO_TFREC = tf.io.gfile.glob(f\"{GCS_PATH}/photo_tfrec/*.tfrec\")\n",
    "print(f\"Monet TFRecords: {len(MONET_TFREC)}  |  Photo TFRecords: {len(PHOTO_TFREC)}\")\n",
    "\n",
    "# Build datasets\n",
    "monet_ds = make_dataset(MONET_TFREC, augment=True)\n",
    "photo_ds = make_dataset(PHOTO_TFREC, augment=False)\n",
    "\n",
    "# Quick sanity‑check visual\n",
    "sample_monet = next(iter(monet_ds.take(1)))[0]\n",
    "sample_photo = next(iter(photo_ds.take(1)))[0]\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow((sample_photo + 1) / 2)\n",
    "plt.title(\"Photo\")\n",
    "plt.axis(False)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow((sample_monet + 1) / 2)\n",
    "plt.title(\"Monet\")\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture – downsample & upsample blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-06T22:37:30.706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# See /src/art_creation_gan/blocks.py for downsample() and upsample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator & Discriminator builders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-06T22:37:30.706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from art_creation_gan import build_generator, build_discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate models under distribution scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-06T22:37:30.706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    monet_generator = build_generator()  # Photo → Monet\n",
    "    photo_generator = build_generator()  # Monet → Photo\n",
    "\n",
    "    monet_discriminator = build_discriminator()\n",
    "    photo_discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo a single forward pass for sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-06T22:37:30.706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "_to_monet = monet_generator(sample_photo[None, ...])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Photo\")\n",
    "plt.imshow(sample_photo * 0.5 + 0.5)\n",
    "plt.axis(False)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Monet-esque Photo\")\n",
    "plt.imshow(_to_monet[0] * 0.5 + 0.5)\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-06T22:37:30.706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from art_creation_gan import CycleGan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-06T22:37:30.706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from art_creation_gan import discriminator_loss, generator_loss, calc_cycle_loss, identity_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    monet_gen_opt = keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    photo_gen_opt = keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    monet_disc_opt = keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "    photo_disc_opt = keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "    cycle_gan_model = CycleGan(\n",
    "        monet_generator, photo_generator, monet_discriminator, photo_discriminator\n",
    "    )\n",
    "    cycle_gan_model.compile(\n",
    "        m_gen_optimizer=monet_gen_opt,\n",
    "        p_gen_optimizer=photo_gen_opt,\n",
    "        m_disc_optimizer=monet_disc_opt,\n",
    "        p_disc_optimizer=photo_disc_opt,\n",
    "        gen_loss_fn=generator_loss,\n",
    "        disc_loss_fn=discriminator_loss,\n",
    "        cycle_loss_fn=calc_cycle_loss,\n",
    "        identity_loss_fn=identity_loss,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-06T22:37:30.707Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.zip((monet_ds, photo_ds)).prefetch(AUTO)\n",
    "_ = cycle_gan_model(next(iter(train_ds.take(1))), training=False)  # Build variables\n",
    "cycle_gan_model.fit(train_ds, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize a few results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-06T22:37:30.707Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 2, figsize=(12, 12))\n",
    "for i, img in enumerate(photo_ds.take(5)):\n",
    "    pred = monet_generator(img, training=False)[0].numpy()\n",
    "    pred = (pred * 127.5 + 127.5).astype(np.uint8)\n",
    "    inp = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n",
    "    ax[i, 0].imshow(inp)\n",
    "    ax[i, 0].set_title(\"Input Photo\")\n",
    "    ax[i, 0].axis(\"off\")\n",
    "    ax[i, 1].imshow(pred)\n",
    "    ax[i, 1].set_title(\"Monet Output\")\n",
    "    ax[i, 1].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate submission zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-06T22:37:30.707Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SUB_DIR = Path(\"/kaggle/working/images\")\n",
    "SUB_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "idx = 0\n",
    "for batch in photo_ds:\n",
    "    fake_batch = monet_generator(batch, training=False).numpy()\n",
    "    for img in fake_batch:\n",
    "        arr = ((img * 127.5) + 127.5).astype(np.uint8)\n",
    "        keras.utils.save_img(SUB_DIR / f\"{idx}.jpg\", arr, scale=False)\n",
    "        idx += 1\n",
    "\n",
    "print(f\"✅ wrote {idx} images\")\n",
    "shutil.make_archive(\"/kaggle/working/images\", \"zip\", SUB_DIR)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 1475600,
     "sourceId": 21755,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31091,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
